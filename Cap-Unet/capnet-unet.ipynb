{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch-summary","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:25:06.311684Z","iopub.execute_input":"2021-06-19T06:25:06.312080Z","iopub.status.idle":"2021-06-19T06:25:15.422375Z","shell.execute_reply.started":"2021-06-19T06:25:06.311999Z","shell.execute_reply":"2021-06-19T06:25:15.421253Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting torch-summary\n  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\nInstalling collected packages: torch-summary\nSuccessfully installed torch-summary-1.4.5\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\nsys.path.append('../input/siim-acr-pneumothorax-segmentation/stage_2_images')\nfrom mask_functions import rle2mask","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:25:15.424522Z","iopub.execute_input":"2021-06-19T06:25:15.424805Z","iopub.status.idle":"2021-06-19T06:25:15.436471Z","shell.execute_reply.started":"2021-06-19T06:25:15.424773Z","shell.execute_reply":"2021-06-19T06:25:15.435419Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2 as cv\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchsummary import summary\nimport torchvision\nimport torchvision.datasets as datasets\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport pydicom\nfrom glob import glob\nimport os","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:25:15.438714Z","iopub.execute_input":"2021-06-19T06:25:15.439614Z","iopub.status.idle":"2021-06-19T06:25:18.243863Z","shell.execute_reply.started":"2021-06-19T06:25:15.439563Z","shell.execute_reply":"2021-06-19T06:25:18.242740Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def squash(x, dim = -1):\n    square_norm = torch.sum(x ** 2, dim = -1, keepdims = True)\n    return square_norm / (1 + square_norm) * x / (torch.sqrt(square_norm) + 1e-6)\n\nclass PrimaryCapsule(nn.Module):\n    def __init__(self, in_channels, out_channels, cap_dim, kernel_size = 5, stride = 2, padding = 2):\n        super().__init__()\n        self.cap_dim = cap_dim\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size = kernel_size, stride = stride, padding = padding)\n    def forward(self, x):\n        x = self.conv(x)\n        number_capsules = x.shape[1] // self.cap_dim\n        x = x.view(-1, number_capsules, self.cap_dim, *(x.shape[2:4]))\n        x = x.permute(0, 3, 4, 1, 2)\n        return squash(x)\nclass ConvCapsule(nn.Module):\n    def __init__(self, input_shape, in_capsules, in_cap_dim, out_capsules, out_cap_dim, kernel_size, stride, padding = 0, iterations = 3):\n        super().__init__()\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.padding = padding\n        self.input_shape = input_shape\n        self.in_capsules = in_capsules\n        self.in_cap_dim = in_cap_dim\n        self.out_capsules = out_capsules\n        self.out_cap_dim = out_cap_dim\n        self.iterations = iterations\n        self.kernel_size = kernel_size\n        self.stride = stride\n        self.W = nn.Parameter(torch.randn(out_capsules * out_cap_dim, in_cap_dim, kernel_size, kernel_size, device = device))\n        self.device = device\n        nn.init.xavier_normal_(self.W)\n\n    def forward(self, x):\n        in_shape = x.shape\n        x = x.permute(0, 3, 4, 1, 2)\n        x = x.reshape(-1, self.in_cap_dim, *self.input_shape)\n        x = F.conv2d(x, self.W, stride = self.stride, padding = self.padding)\n        x = x.view(in_shape[0], in_shape[-2], self.out_capsules, self.out_cap_dim, x.shape[2], x.shape[3])\n        u_hat = x.permute(0, 1, 4, 5, 2, 3)\n\n        b = torch.zeros(u_hat.shape[:-1]).to(self.device)\n        for _ in range(self.iterations - 1):\n            c = F.softmax(b, dim = -2)\n            s = torch.sum(u_hat * c.unsqueeze(-1), dim = 1)\n            v = squash(s)\n            b = b + torch.sum(u_hat * v.unsqueeze(1), dim = -1)\n        c = F.softmax(b, dim = -2)\n        s = torch.sum(u_hat * c.unsqueeze(-1), dim = 1)\n        v = squash(s)\n        return v\nclass ConvTranposeCapsule(nn.Module):\n    def __init__(self, input_shape, in_capsules, in_cap_dim, out_capsules, out_cap_dim, kernel_size, stride, padding = 0, iterations = 3):\n        super().__init__()\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.padding = padding\n        self.input_shape = input_shape\n        self.in_capsules = in_capsules\n        self.in_cap_dim = in_cap_dim\n        self.out_capsules = out_capsules\n        self.out_cap_dim = out_cap_dim\n        self.iterations = iterations\n        self.kernel_size = kernel_size\n        self.stride = stride\n#         self.W = nn.Parameter(torch.randn(in_cap_dim, out_capsules * out_cap_dim, kernel_size, kernel_size).to(device))\n        self.tconv = nn.ConvTranspose2d(in_cap_dim, out_capsules * out_cap_dim, kernel_size = kernel_size, padding = padding, stride = stride)\n        self.device = device\n#         nn.init.xavier_normal_(self.W)\n\n    def forward(self, x):\n        in_shape = x.shape\n        x = x.permute(0, 3, 4, 1, 2)\n        x = x.reshape(-1, self.in_cap_dim, *self.input_shape)\n        x = self.tconv(x)\n        #       x = F.conv_transpose2d(x, self.W, stride = self.stride, padding = self.padding)\n        x = x.view(in_shape[0], in_shape[-2], self.out_capsules, self.out_cap_dim, x.shape[2], x.shape[3])\n        u_hat = x.permute(0, 1, 4, 5, 2, 3)\n\n        b = torch.zeros(u_hat.shape[:-1]).to(self.device)\n        for _ in range(self.iterations - 1):\n            c = F.softmax(b, dim = -2)\n            s = torch.sum(u_hat * c.unsqueeze(-1), dim = 1)\n            v = squash(s)\n            b = b + torch.sum(u_hat * v.unsqueeze(1), dim = -1)\n        c = F.softmax(b, dim = -2)\n        s = torch.sum(u_hat * c.unsqueeze(-1), dim = 1)\n        v = squash(s)\n        return v","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:25:18.245450Z","iopub.execute_input":"2021-06-19T06:25:18.245739Z","iopub.status.idle":"2021-06-19T06:25:18.273557Z","shell.execute_reply.started":"2021-06-19T06:25:18.245710Z","shell.execute_reply":"2021-06-19T06:25:18.272101Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class UpConv(nn.Module):\n    def __init__(self, input_shape, scale_factor, in_capsules, in_cap_dim, out_capsules, out_cap_dim, kernel_size, stride, padding, iterations = 3):\n        super().__init__()\n        self.scale_factor = scale_factor\n        new_shape = (input_shape[0] * scale_factor, input_shape[1] * scale_factor)\n        self.conv_cap = ConvCapsule(new_shape, in_capsules, in_cap_dim, out_capsules, out_cap_dim, kernel_size = kernel_size, padding = padding, stride = stride, iterations = iterations)\n    def forward(self, x):\n        in_dim = x.shape[-1]\n        in_caps = x.shape[-2]\n        h, w = x.shape[1: 3]\n        x = x.permute(0, 3, 4, 1, 2)\n        x = x.reshape(x.shape[0], -1, h, w)\n        x = F.interpolate(x, scale_factor = self.scale_factor)\n        x = x.reshape(x.shape[0], in_caps, in_dim, h * self.scale_factor, w * self.scale_factor)\n        x = x.permute(0, 3, 4, 1, 2)\n        x = self.conv_cap(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:25:18.274933Z","iopub.execute_input":"2021-06-19T06:25:18.275235Z","iopub.status.idle":"2021-06-19T06:25:18.291649Z","shell.execute_reply.started":"2021-06-19T06:25:18.275206Z","shell.execute_reply":"2021-06-19T06:25:18.290821Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def dice_score(inputs, targets, smooth = 1):\n    return (2 * (inputs * targets).sum() + smooth) / (inputs.sum() + targets.sum() + smooth)\ndef dice_loss(inputs, targets, smooth = 1):\n    return 1 - (2 * (inputs * targets).sum() + smooth) / (inputs.sum() + targets.sum() + smooth)\ndef focal_loss(inputs, targets, alpha = 0.8, gamma = 2, reduction = 'none'):\n    assert reduction in ['none', 'mean', 'sum']\n    loss = F.binary_cross_entropy(inputs, targets, reduction = 'none')\n    coeff = (1 - inputs) ** gamma\n    loss = coeff * loss\n    focal_loss = torch.where(targets == 1, loss, loss * alpha)\n    if reduction == \"none\": return focal_loss\n    elif reduction == \"mean\": return focal_loss.mean()\n    elif reduction == \"sum\": return focal_loss.sum()\ndef criterion(inputs, targets, factors = [3, 1, 4], smooth = 1, alpha = 0.8, gamma = 2, reduction = 'mean'):\n    return F.binary_cross_entropy(inputs, targets) * factors[0] \\\n            + dice_loss(inputs, targets, smooth = smooth) * factors[1] \\\n            + focal_loss(inputs, targets, alpha = alpha, gamma = gamma, reduction = reduction) * factors[2]","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:25:18.292705Z","iopub.execute_input":"2021-06-19T06:25:18.293101Z","iopub.status.idle":"2021-06-19T06:25:18.304907Z","shell.execute_reply.started":"2021-06-19T06:25:18.293073Z","shell.execute_reply":"2021-06-19T06:25:18.303975Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def get_conv_shape(input_shape, kernel_size, padding, stride):\n    def fn(x):\n        return (x + 2 * padding - kernel_size) // stride + 1\n    return fn(input_shape[0]), fn(input_shape[1])\ndef get_conv_transpose_shape(input_shape, kernel_size, padding, stride):\n    def fn(x):\n        return stride * (x - 1) - 2 * padding + kernel_size\n    return fn(input_shape[0]), fn(input_shape[1])\ndef get_upconv_shape(input_shape, scale):\n    return input_shape[0] * scale, input_shape[1] * scale\nclass CapUnetNet(nn.Module):\n    def __init__(self, image_shape, in_channels):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels, 32, kernel_size = 5, padding = 2)\n        self.relu1 = nn.ReLU()\n        self.cap1 = PrimaryCapsule(1, 16, 16, kernel_size = 5, stride = 1, padding = 2)\n        self.cap2 = ConvCapsule(image_shape, 1, 16, 2, 16, kernel_size = 5, stride = 2, padding = 2, iterations = 1)\n        out_shape2 = get_conv_shape(image_shape, kernel_size = 5, padding = 2, stride = 2)\n        self.cap2_1 = ConvCapsule(out_shape2, 2, 16, 4, 16, kernel_size = 3, padding = 1, stride = 1)\n        self.cap3 = ConvCapsule(out_shape2, 4, 16, 4, 32, kernel_size = 3, padding = 1, stride = 2)\n        out_shape3 = get_conv_shape(out_shape2, kernel_size = 3, padding = 1, stride = 2)\n        self.cap3_1 = ConvCapsule(out_shape3, 4, 32, 8, 32, kernel_size = 3, padding = 1, stride = 1)\n        self.cap4 = ConvCapsule(out_shape3, 8, 32, 8, 64, kernel_size = 3, padding = 1, stride = 2)\n        out_shape4 = get_conv_shape(out_shape3, kernel_size = 3, padding = 1, stride = 2)\n\n        self.up_cap4 = UpConv(out_shape4, 2, 8, 64, 8, 32, kernel_size = 3, stride = 1, padding = 1)\n        out_up3 = get_upconv_shape(out_shape4, 2)\n        self.up_cap4_1 = ConvCapsule(out_up3, 16, 32, 4, 32, kernel_size = 3, padding = 1, stride = 1)\n        self.up_cap3 = UpConv(out_up3, 2, 4, 32, 4, 16, kernel_size = 3, stride = 1, padding = 1)\n        out_up2 = get_upconv_shape(out_up3, 2)\n        self.up_cap3_1 = ConvCapsule(out_up2, 8, 16, 2, 16, kernel_size = 3, padding = 1, stride = 1)\n        self.up_cap2 = UpConv(out_up2, 2, 2, 16, 1, 16, kernel_size = 3, padding = 1, stride = 1)\n        out_up1 = get_upconv_shape(out_up2, 2)\n        self.re_cap = ConvCapsule(out_up1, 2, 16, 1, 16, kernel_size = 3, padding = 1, stride = 1)\n        self.up_tconv = nn.Conv2d(16, 8, kernel_size = 3, padding = 1)\n        self.up_relu = nn.ReLU()\n        self.re_conv = nn.Conv2d(8, 1, kernel_size = 1)\n\n\n    def forward(self, x):\n#         x = self.conv1(x)\n#         x = self.relu1(x)\n        out_cap1 = self.cap1(x)\n        out_down2 = self.cap2(out_cap1)\n        out_down2_1 = self.cap2_1(out_down2)\n        out_down3 = self.cap3(out_down2_1)\n        out_down3_1 = self.cap3_1(out_down3)\n        out_down4 = self.cap4(out_down3_1)\n\n        out_up3 = self.up_cap4(out_down4)\n        out_cat3 = torch.cat((out_down3_1, out_up3), dim = -2)\n        out_up3_1 = self.up_cap4_1(out_cat3)\n        out_up2 = self.up_cap3(out_up3_1)\n        out_cat2 = torch.cat((out_down2_1, out_up2), dim = -2)\n        out_up2_1 = self.up_cap3_1(out_cat2)\n        out_up1 = self.up_cap2(out_up2_1)\n        out = torch.cat((out_cap1, out_up1), dim = -2)\n        out = self.re_cap(out)\n        out = out_up1.view(*out_up1.shape[:-2], -1)\n        out = out.permute(0, 3, 1, 2)\n        out = self.up_tconv(out)\n        out = self.up_relu(out)\n        out = self.re_conv(out)\n        return torch.sigmoid(out)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:25:18.306468Z","iopub.execute_input":"2021-06-19T06:25:18.307141Z","iopub.status.idle":"2021-06-19T06:25:18.334922Z","shell.execute_reply.started":"2021-06-19T06:25:18.307094Z","shell.execute_reply":"2021-06-19T06:25:18.333980Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"summary(CapUnetNet((512, 512), 1), (1, 512, 512))","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:25:18.338305Z","iopub.execute_input":"2021-06-19T06:25:18.339120Z","iopub.status.idle":"2021-06-19T06:25:34.787775Z","shell.execute_reply.started":"2021-06-19T06:25:18.339059Z","shell.execute_reply":"2021-06-19T06:25:34.786849Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─PrimaryCapsule: 1-1                    [-1, 512, 512, 1, 16]     --\n|    └─Conv2d: 2-1                       [-1, 16, 512, 512]        416\n├─ConvCapsule: 1-2                       [-1, 256, 256, 2, 16]     12,800\n├─ConvCapsule: 1-3                       [-1, 256, 256, 4, 16]     9,216\n├─ConvCapsule: 1-4                       [-1, 128, 128, 4, 32]     18,432\n├─ConvCapsule: 1-5                       [-1, 128, 128, 8, 32]     73,728\n├─ConvCapsule: 1-6                       [-1, 64, 64, 8, 64]       147,456\n├─UpConv: 1-7                            [-1, 128, 128, 8, 32]     --\n|    └─ConvCapsule: 2-2                  [-1, 128, 128, 8, 32]     147,456\n├─ConvCapsule: 1-8                       [-1, 128, 128, 4, 32]     36,864\n├─UpConv: 1-9                            [-1, 256, 256, 4, 16]     --\n|    └─ConvCapsule: 2-3                  [-1, 256, 256, 4, 16]     18,432\n├─ConvCapsule: 1-10                      [-1, 256, 256, 2, 16]     4,608\n├─UpConv: 1-11                           [-1, 512, 512, 1, 16]     --\n|    └─ConvCapsule: 2-4                  [-1, 512, 512, 1, 16]     2,304\n├─ConvCapsule: 1-12                      [-1, 512, 512, 1, 16]     2,304\n├─Conv2d: 1-13                           [-1, 8, 512, 512]         1,160\n├─ReLU: 1-14                             [-1, 8, 512, 512]         --\n├─Conv2d: 1-15                           [-1, 1, 512, 512]         9\n==========================================================================================\nTotal params: 475,185\nTrainable params: 475,185\nNon-trainable params: 0\nTotal mult-adds (M): 408.95\n==========================================================================================\nInput size (MB): 1.00\nForward/backward pass size (MB): 322.00\nParams size (MB): 1.81\nEstimated Total Size (MB): 324.81\n==========================================================================================\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─PrimaryCapsule: 1-1                    [-1, 512, 512, 1, 16]     --\n|    └─Conv2d: 2-1                       [-1, 16, 512, 512]        416\n├─ConvCapsule: 1-2                       [-1, 256, 256, 2, 16]     12,800\n├─ConvCapsule: 1-3                       [-1, 256, 256, 4, 16]     9,216\n├─ConvCapsule: 1-4                       [-1, 128, 128, 4, 32]     18,432\n├─ConvCapsule: 1-5                       [-1, 128, 128, 8, 32]     73,728\n├─ConvCapsule: 1-6                       [-1, 64, 64, 8, 64]       147,456\n├─UpConv: 1-7                            [-1, 128, 128, 8, 32]     --\n|    └─ConvCapsule: 2-2                  [-1, 128, 128, 8, 32]     147,456\n├─ConvCapsule: 1-8                       [-1, 128, 128, 4, 32]     36,864\n├─UpConv: 1-9                            [-1, 256, 256, 4, 16]     --\n|    └─ConvCapsule: 2-3                  [-1, 256, 256, 4, 16]     18,432\n├─ConvCapsule: 1-10                      [-1, 256, 256, 2, 16]     4,608\n├─UpConv: 1-11                           [-1, 512, 512, 1, 16]     --\n|    └─ConvCapsule: 2-4                  [-1, 512, 512, 1, 16]     2,304\n├─ConvCapsule: 1-12                      [-1, 512, 512, 1, 16]     2,304\n├─Conv2d: 1-13                           [-1, 8, 512, 512]         1,160\n├─ReLU: 1-14                             [-1, 8, 512, 512]         --\n├─Conv2d: 1-15                           [-1, 1, 512, 512]         9\n==========================================================================================\nTotal params: 475,185\nTrainable params: 475,185\nNon-trainable params: 0\nTotal mult-adds (M): 408.95\n==========================================================================================\nInput size (MB): 1.00\nForward/backward pass size (MB): 322.00\nParams size (MB): 1.81\nEstimated Total Size (MB): 324.81\n=========================================================================================="},"metadata":{}}]},{"cell_type":"code","source":"class XrayDataset(Dataset):\n    def __init__(self, paths, df, target_shape = (512, 512), mode = 'train', transforms = None):\n        super().__init__()\n        self.paths = paths\n        self.df = df\n        self.target_shape = target_shape\n        self.mode = mode\n        self.transforms = transforms\n        self.data = self.prepare_data()\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, idx):\n        info = self.data[idx]\n        path = info['path']\n        dcmdata = pydicom.dcmread(path)\n        image = dcmdata.pixel_array\n        if self.target_shape is not None:\n            image = cv.resize(image, self.target_shape[::-1], interpolation = cv.INTER_CUBIC)\n        if self.mode == \"test\":\n            image = np.expand_dims(image, 0) / 255.\n            image = image.astype(np.float32)\n            return torch.from_numpy(image)\n        encoded_masks = info['masks']\n        mask = np.zeros(self.target_shape)\n        for encoded_mask in encoded_masks:\n            if encoded_mask != \"-1\":\n                _mask = rle2mask(encoded_mask, 1024, 1024).T\n                _mask = cv.resize(_mask, self.target_shape[::-1], interpolation = cv.INTER_CUBIC)\n                mask[_mask == 255] = 255\n        if self.transforms:\n            aug = self.transforms(image = image, mask = mask)\n            image = aug['image']\n            mask = aug['mask']        \n        image = np.expand_dims(image, 0) / 255.\n        mask = np.expand_dims(mask, 0) / 255.\n        image = image.astype(np.float32)\n        mask = mask.astype(np.float32)\n        return torch.from_numpy(image), torch.from_numpy(mask)\n\n    def prepare_data(self):\n        data = []\n        image_ids = self.df['ImageId'].unique()\n        for image_id in tqdm(image_ids):\n            index = list(filter(lambda x: image_id in self.paths[x], range(len(self.paths))))\n            if len(index) == 0:\n                continue\n            index = index[0]\n            path = self.paths[index]\n            all_chests = self.df[self.df[\"ImageId\"] == image_id]\n            encode_rois = []\n            for _, row in all_chests.iterrows():\n                encode_rois.append(row[\" EncodedPixels\"])\n            data.append({\n                'image_id': image_id,\n                'path': path,\n                'masks': encode_rois\n            })\n        return data","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:25:34.789332Z","iopub.execute_input":"2021-06-19T06:25:34.789676Z","iopub.status.idle":"2021-06-19T06:25:34.807224Z","shell.execute_reply.started":"2021-06-19T06:25:34.789645Z","shell.execute_reply":"2021-06-19T06:25:34.805672Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"paths = glob(os.path.join('..', 'input', 'siim-train-test', 'dicom-images-train', '*', '*', '*.dcm'))","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:25:34.808960Z","iopub.execute_input":"2021-06-19T06:25:34.809540Z","iopub.status.idle":"2021-06-19T06:26:30.080413Z","shell.execute_reply.started":"2021-06-19T06:25:34.809484Z","shell.execute_reply":"2021-06-19T06:26:30.079248Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/siim-train-test/train-rle.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:26:30.081938Z","iopub.execute_input":"2021-06-19T06:26:30.082346Z","iopub.status.idle":"2021-06-19T06:26:30.210620Z","shell.execute_reply.started":"2021-06-19T06:26:30.082303Z","shell.execute_reply":"2021-06-19T06:26:30.209593Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nINIT_LR = 1e-5\nBATCH_SIZE = 2\nTRAIN_RATE = 0.75\nEPOCHS = 20","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:26:30.211876Z","iopub.execute_input":"2021-06-19T06:26:30.212174Z","iopub.status.idle":"2021-06-19T06:26:30.216935Z","shell.execute_reply.started":"2021-06-19T06:26:30.212146Z","shell.execute_reply":"2021-06-19T06:26:30.215949Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_paths, val_paths = train_test_split(paths, train_size = TRAIN_RATE)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:26:30.218384Z","iopub.execute_input":"2021-06-19T06:26:30.218931Z","iopub.status.idle":"2021-06-19T06:26:30.242737Z","shell.execute_reply.started":"2021-06-19T06:26:30.218885Z","shell.execute_reply":"2021-06-19T06:26:30.241606Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_dataset = XrayDataset(train_paths, df)\nval_dataset = XrayDataset(val_paths, df, mode = 'val')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:26:30.244124Z","iopub.execute_input":"2021-06-19T06:26:30.244484Z","iopub.status.idle":"2021-06-19T06:28:08.242774Z","shell.execute_reply.started":"2021-06-19T06:26:30.244447Z","shell.execute_reply":"2021-06-19T06:28:08.242061Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"100%|██████████| 12047/12047 [01:16<00:00, 157.85it/s]\n100%|██████████| 12047/12047 [00:21<00:00, 556.44it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size = BATCH_SIZE)\nval_loader = DataLoader(val_dataset, batch_size = BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:28:08.243703Z","iopub.execute_input":"2021-06-19T06:28:08.243963Z","iopub.status.idle":"2021-06-19T06:28:08.248207Z","shell.execute_reply.started":"2021-06-19T06:28:08.243936Z","shell.execute_reply":"2021-06-19T06:28:08.247469Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"model = CapUnetNet((512, 512), 1).to(DEVICE)\noptimizer = torch.optim.Adam(model.parameters(), lr = INIT_LR)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:28:08.249501Z","iopub.execute_input":"2021-06-19T06:28:08.249770Z","iopub.status.idle":"2021-06-19T06:28:08.278023Z","shell.execute_reply.started":"2021-06-19T06:28:08.249744Z","shell.execute_reply":"2021-06-19T06:28:08.276927Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"ITERS_PER_EPOCH = len(train_paths) // BATCH_SIZE","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:28:08.279514Z","iopub.execute_input":"2021-06-19T06:28:08.279939Z","iopub.status.idle":"2021-06-19T06:28:08.284682Z","shell.execute_reply.started":"2021-06-19T06:28:08.279896Z","shell.execute_reply":"2021-06-19T06:28:08.283558Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    bar = tqdm(range(ITERS_PER_EPOCH))\n    for i, (images, masks) in enumerate(train_loader):\n        images = images.to(DEVICE)\n        masks = masks.to(DEVICE)\n        pred_masks = model(images)\n        loss = criterion(pred_masks, masks)\n        loss.backward()\n        optimizer.step()\n        bar.set_description(f'epoch {epoch + 1} iter {i + 1} loss {loss.cpu().detach().item()}')\n    with torch.no_grad():\n        acc_loss = 0\n        acc_dice = 0\n        count = 0\n        for images, masks in tqdm(val_loader):\n            images = images.to(torch.float32).to(DEVICE)\n            masks  = masks.to(torch.float32).to(DEVICE)\n            pred_masks = model(images)\n            loss = criterion(pred_masks, masks)\n            acc_dice += dice_score(pred_masks, masks)\n            acc_loss += loss.cpu().item()\n            count += 1\n        acc_loss /= count\n        acc_dice /= count\n        print(f'[VAL] epoch {epoch} loss {acc_loss} dice {acc_dice}')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:28:08.286025Z","iopub.execute_input":"2021-06-19T06:28:08.286456Z","iopub.status.idle":"2021-06-19T06:29:03.526057Z","shell.execute_reply.started":"2021-06-19T06:28:08.286413Z","shell.execute_reply":"2021-06-19T06:29:03.524621Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"epoch 1 iter 1 loss 3.8499557971954346:   0%|          | 0/4533 [00:38<?, ?it/s]","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-42a8c9267541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mpred_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-0a93b2a4db5b>\u001b[0m in \u001b[0;36mcriterion\u001b[0;34m(inputs, targets, factors, smooth, alpha, gamma, reduction)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0mdice_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmooth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;34m+\u001b[0m \u001b[0mfocal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mfactors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2525\u001b[0m     return torch._C._nn.binary_cross_entropy(\n\u001b[0;32m-> 2526\u001b[0;31m         input, target, weight, reduction_enum)\n\u001b[0m\u001b[1;32m   2527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"],"ename":"RuntimeError","evalue":"all elements of input should be between 0 and 1","output_type":"error"}]},{"cell_type":"code","source":"pred_masks","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:29:16.597288Z","iopub.execute_input":"2021-06-19T06:29:16.597812Z","iopub.status.idle":"2021-06-19T06:29:16.611177Z","shell.execute_reply.started":"2021-06-19T06:29:16.597779Z","shell.execute_reply":"2021-06-19T06:29:16.610031Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"tensor([[[[nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan],\n          ...,\n          [nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan]]],\n\n\n        [[[nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan],\n          ...,\n          [nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan],\n          [nan, nan, nan,  ..., nan, nan, nan]]]], grad_fn=<SigmoidBackward>)"},"metadata":{}}]},{"cell_type":"code","source":"for p in model.parameters():\n    if p.requires_grad:\n         print(p.name, p.data)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:30:31.738626Z","iopub.execute_input":"2021-06-19T06:30:31.739036Z","iopub.status.idle":"2021-06-19T06:30:31.832065Z","shell.execute_reply.started":"2021-06-19T06:30:31.739000Z","shell.execute_reply":"2021-06-19T06:30:31.829132Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"None tensor([[[[-3.5453e-02,  8.0910e-02,  7.8410e-03, -9.3192e-02, -1.6132e-01],\n          [-7.6303e-02, -1.4904e-01,  9.8070e-02, -4.7112e-02,  6.1998e-02],\n          [ 1.9028e-01,  1.2712e-01, -8.4803e-02,  6.3459e-02,  3.6548e-02],\n          [-1.7687e-01, -1.7444e-01,  1.7430e-01,  1.7025e-02, -5.2179e-02],\n          [ 6.9308e-02,  3.1164e-02,  1.5894e-01, -6.4666e-02,  9.3455e-03]]],\n\n\n        [[[ 1.5420e-01,  1.2863e-01,  5.9149e-02, -9.1593e-02, -5.4059e-02],\n          [-8.3433e-02, -1.6336e-01,  1.0875e-01,  1.5094e-01, -2.4183e-03],\n          [ 1.3701e-01,  7.2726e-02,  4.5911e-02, -5.0948e-02, -2.8501e-03],\n          [ 1.3533e-01,  2.6575e-02,  5.4932e-02,  5.5155e-02,  1.3815e-01],\n          [ 3.4955e-02,  3.8531e-02, -3.2546e-02, -1.9486e-01, -1.0140e-01]]],\n\n\n        [[[ 1.2958e-01, -1.2638e-01, -1.4096e-01,  1.6479e-01, -1.8333e-01],\n          [ 1.9504e-01,  2.4040e-02, -9.4551e-02, -1.6500e-01, -1.7157e-01],\n          [ 3.8113e-02, -1.5854e-01,  2.9875e-02,  9.8179e-02, -1.4672e-01],\n          [ 8.6629e-03, -3.7058e-02,  1.8007e-01, -1.2166e-01, -6.3102e-02],\n          [-1.7073e-01,  1.9405e-01, -4.9630e-02, -3.1722e-02,  1.9247e-01]]],\n\n\n        [[[-1.2383e-02,  1.1761e-01, -1.2275e-01, -1.1890e-01,  1.7726e-01],\n          [-1.4510e-01, -4.4188e-02,  2.1577e-02,  1.4733e-01,  3.6244e-02],\n          [ 8.6048e-03, -9.3051e-02, -3.8769e-02,  9.1481e-02,  1.4557e-02],\n          [-1.2621e-01, -1.5096e-01,  1.0481e-01,  1.3109e-01, -1.6971e-01],\n          [-1.4159e-01, -2.5202e-02,  8.6740e-03,  7.7928e-02,  1.9281e-01]]],\n\n\n        [[[-1.3887e-01,  1.4694e-01,  1.9460e-01, -2.1495e-02,  4.5280e-02],\n          [-6.1342e-02,  2.2388e-02, -1.1497e-02, -9.8762e-02,  6.9690e-02],\n          [-1.1293e-01, -1.3465e-01, -3.6359e-02, -4.2490e-02, -1.6258e-01],\n          [ 1.2412e-01,  1.7276e-02,  4.3024e-02, -1.1807e-01,  1.9649e-01],\n          [ 1.8680e-01, -5.5395e-02,  8.3079e-02,  1.7430e-01,  2.7683e-02]]],\n\n\n        [[[ 1.3048e-01,  3.6014e-02, -1.3989e-01,  8.8548e-02,  1.6686e-01],\n          [ 1.3357e-01, -1.9813e-01,  3.8319e-02, -6.2980e-02,  1.4541e-01],\n          [ 1.2532e-02, -6.6720e-02, -1.1365e-02, -4.7517e-02, -1.0219e-01],\n          [-2.3884e-02,  1.9701e-01,  9.3777e-02,  8.1541e-02, -1.7127e-01],\n          [ 2.6022e-02,  1.5100e-01,  1.4219e-01, -2.8839e-02,  1.0132e-01]]],\n\n\n        [[[ 1.8485e-01, -9.4759e-03, -1.6990e-01,  2.9430e-02, -1.5166e-01],\n          [ 7.3315e-02,  1.5055e-01, -8.6742e-02,  4.8663e-02, -9.9087e-02],\n          [ 1.9329e-01,  1.7207e-01,  1.5011e-01,  1.7367e-01, -1.3742e-01],\n          [ 8.0795e-02,  8.6399e-02, -1.8049e-01,  8.8401e-02, -2.5965e-02],\n          [ 1.2456e-01,  1.1546e-01, -1.3635e-01,  2.1183e-02,  1.4054e-01]]],\n\n\n        [[[ 1.3347e-01,  6.5360e-02,  1.3251e-01, -1.2327e-01, -1.8143e-01],\n          [-1.6844e-01,  1.1329e-01, -1.4253e-01,  1.8120e-01,  1.6771e-01],\n          [-8.2293e-02, -1.7848e-01, -1.7981e-01,  6.4323e-02,  7.4119e-02],\n          [-3.9244e-05,  6.2035e-02,  1.5977e-01, -8.8864e-02,  5.8200e-02],\n          [-6.3334e-02, -3.2232e-02,  1.2743e-01,  6.2094e-02, -1.7918e-02]]],\n\n\n        [[[ 1.8739e-01,  1.5157e-01,  1.1270e-01, -4.3681e-02, -7.4963e-02],\n          [ 1.6879e-01,  6.9833e-02,  5.4122e-02,  1.7653e-01,  7.3538e-03],\n          [-5.0228e-02,  1.6954e-01, -5.0621e-02, -9.9890e-02, -1.0764e-01],\n          [ 2.2039e-02, -1.7958e-01,  8.3483e-02,  1.0900e-01, -6.4100e-02],\n          [ 3.0203e-02, -1.5473e-02, -5.9034e-02, -1.2967e-01, -1.0483e-01]]],\n\n\n        [[[ 3.6410e-02, -4.2746e-02, -1.7956e-01,  5.1040e-02,  5.5555e-02],\n          [ 1.7129e-01,  1.9897e-01,  1.8507e-01,  1.5037e-01,  1.8741e-01],\n          [-1.3046e-01,  1.9874e-01,  5.3467e-02, -1.1703e-01,  8.2335e-02],\n          [-1.2366e-01,  1.8263e-01, -5.3299e-02, -1.6024e-01, -2.5585e-02],\n          [-1.7281e-01, -9.5235e-02, -5.9780e-03, -9.0115e-02, -7.3059e-02]]],\n\n\n        [[[-1.6781e-01,  1.4871e-01,  1.4537e-01, -1.8783e-01, -1.6623e-01],\n          [ 1.9572e-01,  1.0930e-01, -1.1542e-01,  1.5769e-01, -7.3146e-02],\n          [ 1.4592e-01,  7.8768e-02, -1.4431e-01, -1.0006e-02, -7.1725e-02],\n          [ 9.8380e-02, -1.9350e-02,  6.1995e-02,  1.8381e-01, -1.9662e-01],\n          [-1.9267e-01, -9.5254e-02,  3.4181e-02,  5.9202e-02,  2.0091e-02]]],\n\n\n        [[[ 7.9986e-02,  1.5273e-01, -1.1088e-01, -1.5503e-01,  1.3548e-01],\n          [ 6.8317e-02,  6.4410e-03, -8.4096e-02,  1.8412e-01,  1.3082e-01],\n          [ 8.1665e-02,  1.7372e-01, -1.0033e-01,  5.2903e-02,  2.9322e-02],\n          [-8.5746e-02, -2.6807e-02, -1.0565e-01,  1.8999e-01, -1.3435e-01],\n          [-6.9786e-02, -6.0992e-02,  1.0641e-01, -6.3498e-02,  9.4109e-02]]],\n\n\n        [[[ 7.7778e-02,  1.5254e-01,  4.7453e-02,  1.4334e-01, -1.1068e-01],\n          [-1.0114e-01, -1.6234e-01, -3.8406e-02, -1.2467e-01, -7.4089e-02],\n          [-1.0780e-02,  1.6187e-01, -7.6125e-02,  1.4819e-01,  7.8472e-02],\n          [-7.1719e-02,  1.1176e-01, -1.5569e-02, -5.2254e-02,  9.8161e-02],\n          [-7.6488e-02,  1.4566e-01, -1.7303e-01,  1.8951e-01, -1.6184e-01]]],\n\n\n        [[[-1.1504e-01,  5.4679e-03,  5.5392e-02, -9.3743e-02, -7.1242e-02],\n          [-9.1333e-02,  1.3053e-01, -4.1919e-03, -1.7321e-01, -1.6063e-02],\n          [ 7.2795e-02, -1.1229e-01,  4.3230e-02, -1.9107e-01,  3.0738e-02],\n          [-1.0717e-01,  5.0895e-02,  1.7190e-01, -2.3597e-02,  7.8680e-02],\n          [ 1.5158e-01,  8.7187e-02,  4.1071e-02, -1.4467e-01,  2.2284e-02]]],\n\n\n        [[[ 9.7658e-02,  8.7723e-02, -1.5799e-01,  1.9578e-01, -1.4031e-01],\n          [-1.1435e-01,  1.7162e-01, -5.5865e-02, -7.2523e-02,  1.1078e-01],\n          [-8.5837e-02,  8.7118e-02,  3.8170e-02,  3.6484e-02, -1.2908e-01],\n          [ 1.0009e-02,  5.7464e-02,  1.2620e-01, -7.6340e-02,  2.8302e-02],\n          [ 1.3755e-01, -1.9449e-01, -1.3791e-01, -6.6476e-02, -2.2172e-02]]],\n\n\n        [[[ 8.1891e-02,  1.0928e-01,  1.7177e-01, -1.6418e-01,  1.9520e-01],\n          [ 5.4495e-02, -1.3442e-01, -1.5592e-01,  8.2797e-02, -1.0042e-01],\n          [ 1.4116e-01, -2.0928e-02, -1.8323e-01,  1.2859e-01, -7.3882e-02],\n          [-1.0689e-01,  1.4438e-01,  4.8239e-02,  2.2093e-02,  1.9880e-02],\n          [-1.9868e-01,  9.8325e-02, -1.1883e-01,  1.4354e-01, -1.3251e-01]]],\n\n\n        [[[-7.1335e-02,  8.2044e-02, -1.4652e-02, -1.6925e-01,  1.3985e-01],\n          [-7.5463e-02,  1.9095e-01, -2.0412e-02,  1.3763e-01, -1.0155e-03],\n          [ 7.1772e-02,  2.2561e-02,  1.8209e-01,  7.3863e-02, -3.4419e-02],\n          [-1.9644e-01,  8.2205e-02, -1.6473e-01,  1.4014e-01, -1.6914e-01],\n          [-1.7776e-01, -1.5307e-01, -9.4888e-02,  1.9823e-01,  2.6839e-03]]],\n\n\n        [[[-1.6301e-01,  3.1124e-02,  1.7383e-01, -1.6205e-01, -1.9827e-01],\n          [ 9.7109e-02,  5.5202e-02,  1.6737e-01, -5.6392e-02, -4.7725e-02],\n          [ 6.1228e-02,  1.0494e-01,  1.3979e-01,  1.9619e-01,  1.2260e-01],\n          [ 1.7372e-01, -6.4672e-02,  1.7731e-01, -7.3820e-02,  1.9385e-01],\n          [ 7.7988e-02, -1.7858e-01, -1.6745e-01,  1.8454e-01,  1.0591e-01]]],\n\n\n        [[[ 5.2882e-02, -1.1588e-01, -1.1287e-01,  1.4224e-01, -7.2192e-02],\n          [ 9.6873e-02, -1.2406e-01, -4.5505e-02,  1.1510e-01, -4.4636e-02],\n          [-7.7853e-02,  1.3051e-01,  1.7584e-01, -1.5464e-01,  1.3155e-02],\n          [-1.5094e-01,  7.0110e-02, -1.4369e-01, -6.8611e-02,  3.4870e-03],\n          [ 1.0818e-01, -1.5315e-01, -3.6998e-02,  6.7208e-02, -1.9968e-01]]],\n\n\n        [[[ 1.2509e-01,  1.3810e-01, -1.4328e-01,  1.7280e-01, -9.7871e-02],\n          [ 8.0863e-02,  1.8396e-01,  2.7919e-02, -1.5517e-01,  1.0742e-01],\n          [ 5.0889e-02,  1.4306e-01,  1.4161e-01,  9.6964e-02,  1.0457e-01],\n          [ 1.9511e-01,  5.2069e-02,  2.9617e-02,  9.5039e-02, -5.1739e-02],\n          [-4.6296e-02,  6.6866e-02, -1.6889e-01,  8.6674e-02,  1.7459e-01]]],\n\n\n        [[[ 1.2876e-01, -2.4870e-02,  1.0944e-01, -1.1098e-01,  1.8680e-01],\n          [ 1.7828e-01, -2.1531e-02, -1.6341e-01,  5.5672e-02,  8.7568e-02],\n          [-4.0116e-02,  1.2101e-01, -2.7347e-02,  2.4040e-02,  6.8492e-02],\n          [-8.4019e-02, -4.9461e-02,  1.6826e-02, -5.4418e-02,  1.1638e-01],\n          [ 8.1364e-02,  1.3308e-01, -1.9457e-01,  4.9551e-02, -1.9530e-01]]],\n\n\n        [[[-1.7730e-01,  1.6758e-01,  1.8003e-01, -1.8267e-01, -1.6928e-01],\n          [ 1.2748e-02, -1.0863e-01,  1.9435e-01,  5.7008e-02, -1.6103e-01],\n          [ 1.3903e-01, -1.1981e-02,  9.7863e-02,  1.8138e-01, -1.2558e-01],\n          [ 1.4618e-01, -6.5099e-02,  7.9573e-02, -5.4910e-03,  1.6393e-01],\n          [-1.7878e-01,  8.4223e-02,  2.9704e-02, -1.5650e-01, -1.5836e-01]]],\n\n\n        [[[ 4.1872e-02, -1.0313e-01, -4.8972e-02, -8.2031e-02, -6.0148e-02],\n          [-3.0292e-02,  1.9767e-01,  1.9957e-01,  1.6409e-01, -1.8241e-01],\n          [-1.4294e-02, -7.2346e-02,  1.3540e-01,  5.4239e-03, -1.2242e-01],\n          [ 1.9628e-02, -1.2309e-01, -1.7267e-01, -1.9477e-01,  1.7109e-01],\n          [ 1.5293e-01, -7.4413e-02, -1.6880e-01, -4.3134e-02,  1.7263e-01]]],\n\n\n        [[[ 1.4486e-01, -6.8120e-02, -7.6030e-02,  1.6737e-01, -1.8482e-01],\n          [-3.9868e-02, -3.9774e-02,  5.5272e-02, -1.8566e-01, -1.4293e-02],\n          [-1.7695e-01,  9.1586e-02,  3.6882e-02, -8.2362e-02,  1.0758e-01],\n          [-8.8766e-02, -1.9440e-01,  5.3039e-02, -1.0558e-01, -1.9196e-01],\n          [ 1.7884e-02, -7.7816e-02, -1.0078e-01,  1.8889e-02,  1.6913e-01]]],\n\n\n        [[[-1.0472e-02, -8.3715e-02,  5.6334e-02, -1.1307e-01,  1.7556e-01],\n          [ 1.1567e-01,  1.1341e-01, -1.7747e-01,  3.2881e-02, -1.0675e-01],\n          [-1.1029e-01, -4.8880e-02, -1.1223e-01,  1.0778e-02,  4.5687e-02],\n          [-1.0162e-01, -1.7583e-01,  1.3698e-01,  1.8168e-01,  1.8001e-01],\n          [-1.8360e-01, -1.2927e-01,  3.9127e-02, -1.4712e-02, -1.1508e-01]]],\n\n\n        [[[ 8.6316e-03,  3.9568e-03, -6.6053e-03, -1.2046e-01, -1.7669e-01],\n          [-2.5534e-02,  1.1063e-01,  1.7239e-02,  1.4921e-01,  3.8667e-02],\n          [-9.2482e-02, -7.7521e-02,  1.7488e-01, -7.7973e-02,  3.6749e-02],\n          [-1.7882e-01, -3.7139e-02,  3.9656e-02,  6.5786e-02, -3.4060e-02],\n          [-1.7199e-01, -1.9756e-01,  8.0036e-02,  8.6568e-02,  1.8554e-01]]],\n\n\n        [[[ 1.5128e-01, -1.5640e-01, -1.9511e-01,  1.2056e-01,  6.0634e-02],\n          [ 1.6913e-01,  1.6924e-01, -1.9324e-01, -1.6553e-01,  1.4161e-01],\n          [-1.7162e-01,  1.1035e-01, -5.1052e-02, -8.2806e-02,  1.9232e-01],\n          [-1.2377e-01, -1.7012e-01, -1.1938e-01, -1.1929e-01,  4.8064e-02],\n          [ 5.1046e-02, -1.4688e-01, -1.2293e-01, -9.6218e-02, -3.2032e-02]]],\n\n\n        [[[ 1.1649e-01, -8.7907e-02,  7.4611e-03,  6.7977e-03,  8.0124e-02],\n          [-1.7459e-01, -3.6494e-03, -7.9158e-02,  1.0509e-01, -1.3924e-01],\n          [-9.2183e-02, -1.7531e-01, -9.8104e-02,  1.3199e-01,  2.1883e-02],\n          [ 5.4585e-02, -6.0885e-02, -1.0165e-01,  2.9277e-02, -4.8446e-02],\n          [ 1.9212e-01,  1.3417e-01,  1.1604e-01,  1.5558e-01,  3.1675e-02]]],\n\n\n        [[[ 5.1671e-02,  1.6402e-01,  5.4894e-02, -1.1210e-01,  6.4954e-02],\n          [ 1.5583e-02, -1.4863e-01, -1.1239e-01,  5.1711e-02,  1.6537e-01],\n          [-5.4699e-02,  3.6029e-02, -3.2406e-02,  8.1060e-03,  1.1970e-02],\n          [-1.7132e-01, -4.7560e-02,  1.7741e-01,  6.2696e-02,  9.2483e-02],\n          [-7.9459e-02,  1.5053e-01, -6.2732e-03,  1.1722e-01, -3.2514e-02]]],\n\n\n        [[[ 1.8565e-01, -6.5087e-02, -3.7783e-03, -1.4934e-01,  1.9939e-01],\n          [ 1.5402e-01, -1.4054e-01,  8.6244e-02, -3.2141e-02, -5.7889e-02],\n          [ 1.0451e-01,  5.2366e-03, -1.0883e-01,  8.6413e-02, -8.3169e-02],\n          [ 1.4521e-01, -1.3858e-01,  1.8387e-02, -1.5940e-02, -1.3826e-01],\n          [-1.3542e-01, -1.8003e-01,  1.4310e-02, -6.0747e-02,  5.2406e-02]]],\n\n\n        [[[ 6.1570e-03, -2.5971e-03, -3.0417e-02, -3.8685e-02, -2.9692e-02],\n          [-2.7856e-02, -7.3658e-02,  1.6375e-01,  1.8477e-01, -7.0492e-02],\n          [-1.4348e-01, -4.5097e-03, -6.9706e-02,  2.2426e-02,  1.9753e-01],\n          [ 1.6374e-02,  1.8595e-03,  1.6358e-01,  1.2203e-02, -8.2420e-02],\n          [-1.5075e-01,  1.9887e-02,  6.5940e-02, -1.6359e-01, -1.6627e-01]]],\n\n\n        [[[-1.2945e-02, -4.9618e-02, -1.2494e-01, -1.1021e-01, -9.9798e-02],\n          [ 1.2316e-01, -1.3837e-02, -1.7145e-01, -1.2706e-01, -1.4298e-01],\n          [ 6.6818e-02,  1.6751e-01, -1.9174e-01, -3.9090e-02,  1.5889e-01],\n          [-7.2919e-02, -1.5852e-01, -1.7728e-01,  3.4042e-02,  1.6673e-02],\n          [-1.1397e-01, -1.4745e-03, -3.1669e-02, -6.8195e-02,  1.2433e-01]]]])\nNone tensor([ 0.0316,  0.1217,  0.1907, -0.0796, -0.1756,  0.1968,  0.1717,  0.0613,\n        -0.0118, -0.0615,  0.1001, -0.1466,  0.0366, -0.1098,  0.0041, -0.0765,\n        -0.0982,  0.0194, -0.1241, -0.1693, -0.1520,  0.0659,  0.0402,  0.1964,\n         0.0949,  0.1179,  0.1955,  0.1822,  0.1406,  0.0044,  0.0734, -0.0819])\nNone tensor([[[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]]])\nNone tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\nNone tensor([[[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        ...,\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]],\n\n\n        [[[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]],\n\n         [[nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan],\n          [nan, nan, nan, nan, nan]]]])\nNone tensor([[[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        ...,\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]]])\nNone tensor([[[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        ...,\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]]])\nNone tensor([[[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        ...,\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]]])\nNone tensor([[[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        ...,\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]]])\nNone tensor([[[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        ...,\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]]])\nNone tensor([[[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        ...,\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]]])\nNone tensor([[[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        ...,\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]]])\nNone tensor([[[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        ...,\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]]])\nNone tensor([[[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        ...,\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]],\n\n\n        [[[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         ...,\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]],\n\n         [[nan, nan, nan],\n          [nan, nan, nan],\n          [nan, nan, nan]]]])\nNone tensor([[[[-0.0409, -0.0821, -0.1248],\n          [-0.1453, -0.1227,  0.2112],\n          [-0.0550,  0.1768,  0.0337]],\n\n         [[ 0.0190, -0.0506,  0.0861],\n          [ 0.0314,  0.0356,  0.1918],\n          [ 0.0256,  0.1319, -0.0565]],\n\n         [[ 0.0864, -0.0168,  0.1124],\n          [ 0.0596,  0.0672, -0.0446],\n          [-0.0708, -0.0512, -0.0723]],\n\n         ...,\n\n         [[ 0.0348, -0.0022, -0.0609],\n          [-0.0403, -0.0670, -0.0927],\n          [-0.1222,  0.0996,  0.1152]],\n\n         [[-0.1152, -0.0265, -0.0824],\n          [-0.1135, -0.0702, -0.0338],\n          [-0.0158,  0.1587, -0.0898]],\n\n         [[-0.0077,  0.1189,  0.1066],\n          [-0.0213, -0.0476,  0.0372],\n          [-0.0743,  0.0008,  0.0797]]],\n\n\n        [[[ 0.0497, -0.0299,  0.0077],\n          [-0.0732, -0.0335, -0.0983],\n          [-0.0325,  0.0062, -0.0149]],\n\n         [[ 0.0996,  0.0184, -0.1485],\n          [-0.0964,  0.0351, -0.0726],\n          [-0.0125,  0.0843,  0.1876]],\n\n         [[ 0.1361, -0.0359, -0.1279],\n          [-0.0062, -0.0688, -0.0017],\n          [ 0.0483, -0.0300, -0.1648]],\n\n         ...,\n\n         [[ 0.0215, -0.0254, -0.0510],\n          [ 0.0567,  0.1075, -0.0133],\n          [ 0.1141,  0.0717,  0.0433]],\n\n         [[-0.0600,  0.0633, -0.0185],\n          [ 0.0396,  0.0699,  0.0020],\n          [-0.0588, -0.0198,  0.0252]],\n\n         [[ 0.1188, -0.0842,  0.1143],\n          [-0.0487, -0.0283, -0.0140],\n          [-0.1446,  0.0175,  0.2861]]],\n\n\n        [[[ 0.0832,  0.1115,  0.0194],\n          [ 0.0935, -0.0459,  0.0511],\n          [-0.0238,  0.0583,  0.2354]],\n\n         [[ 0.0294,  0.0456,  0.0190],\n          [ 0.0099, -0.0659,  0.1782],\n          [-0.0227,  0.0653,  0.0529]],\n\n         [[ 0.0896,  0.0861,  0.0112],\n          [ 0.0606, -0.0470,  0.0950],\n          [ 0.0250, -0.0596, -0.0148]],\n\n         ...,\n\n         [[-0.0186,  0.0231,  0.0815],\n          [-0.0427,  0.1780,  0.0506],\n          [ 0.0182,  0.0534,  0.0992]],\n\n         [[ 0.0609,  0.1318, -0.1790],\n          [ 0.0667, -0.0462, -0.0477],\n          [-0.1129,  0.0676,  0.0458]],\n\n         [[ 0.1240,  0.0259,  0.0115],\n          [ 0.0326, -0.0084,  0.0549],\n          [ 0.0172,  0.0236, -0.0494]]],\n\n\n        ...,\n\n\n        [[[-0.0348,  0.0619,  0.1237],\n          [ 0.1905, -0.0829, -0.0393],\n          [ 0.0372, -0.0807,  0.0342]],\n\n         [[-0.0639,  0.0830,  0.0632],\n          [-0.0525, -0.0737, -0.1029],\n          [-0.0761,  0.1543, -0.1159]],\n\n         [[ 0.0155,  0.0022,  0.0080],\n          [-0.1273, -0.1649,  0.0487],\n          [-0.0467,  0.0551, -0.0900]],\n\n         ...,\n\n         [[-0.0334,  0.0276, -0.0838],\n          [ 0.1396,  0.1453,  0.0358],\n          [-0.0063,  0.0146, -0.0526]],\n\n         [[-0.0184, -0.0861, -0.1137],\n          [-0.0895, -0.0133,  0.0910],\n          [-0.1133, -0.0330,  0.0340]],\n\n         [[ 0.0548, -0.0306, -0.0491],\n          [-0.0608, -0.0022, -0.1816],\n          [-0.1097, -0.0154,  0.0860]]],\n\n\n        [[[-0.0865, -0.0824,  0.0533],\n          [-0.1686, -0.0982, -0.1294],\n          [ 0.0592, -0.0375, -0.1197]],\n\n         [[-0.0095, -0.1349,  0.0197],\n          [-0.0808, -0.2336,  0.0848],\n          [-0.0840, -0.1714,  0.0598]],\n\n         [[ 0.1393, -0.0369, -0.0244],\n          [ 0.0190,  0.0527, -0.0494],\n          [-0.0095,  0.1228, -0.0122]],\n\n         ...,\n\n         [[ 0.0020,  0.0145, -0.0174],\n          [ 0.1534,  0.0098,  0.1270],\n          [-0.0390, -0.1061, -0.0463]],\n\n         [[-0.1496,  0.0207, -0.0676],\n          [ 0.0876,  0.2163, -0.1100],\n          [-0.0318, -0.1646, -0.1302]],\n\n         [[-0.0004, -0.0262, -0.0864],\n          [ 0.0751,  0.0326,  0.0394],\n          [-0.0300,  0.0197, -0.0270]]],\n\n\n        [[[-0.0627, -0.0957, -0.0065],\n          [-0.0806,  0.0640,  0.0396],\n          [ 0.0777,  0.0543,  0.0060]],\n\n         [[ 0.0682,  0.0561,  0.1118],\n          [-0.1246,  0.0303,  0.1329],\n          [ 0.0379, -0.0052,  0.0054]],\n\n         [[ 0.0408,  0.0058, -0.0078],\n          [-0.1632, -0.1791, -0.1722],\n          [ 0.0610, -0.0176, -0.0556]],\n\n         ...,\n\n         [[-0.0583,  0.1374, -0.0158],\n          [-0.0763,  0.1036, -0.0221],\n          [ 0.0600,  0.0112,  0.0716]],\n\n         [[-0.0692, -0.0124,  0.0368],\n          [ 0.1334,  0.1683,  0.0895],\n          [-0.0685,  0.0112,  0.0111]],\n\n         [[-0.0179, -0.0976,  0.0489],\n          [ 0.1753, -0.0294, -0.0043],\n          [ 0.0534, -0.1280, -0.0311]]]])\nNone tensor([[[[-0.0609, -0.0143,  0.0503],\n          [-0.0825, -0.0123,  0.0640],\n          [ 0.0210, -0.0430,  0.0043]],\n\n         [[ 0.0407, -0.0245, -0.0557],\n          [-0.0660,  0.0006, -0.0360],\n          [-0.0666,  0.0008,  0.0008]],\n\n         [[-0.0610, -0.0314,  0.0349],\n          [-0.0730, -0.0491, -0.0351],\n          [-0.0478, -0.0321,  0.0714]],\n\n         ...,\n\n         [[ 0.0210, -0.0036,  0.0504],\n          [-0.0826,  0.0499, -0.0298],\n          [ 0.0147, -0.0435, -0.0825]],\n\n         [[-0.0735,  0.0535,  0.0374],\n          [ 0.0493,  0.0740,  0.0808],\n          [ 0.0006,  0.0198,  0.0285]],\n\n         [[ 0.0215,  0.0215, -0.0459],\n          [ 0.0625,  0.0419, -0.0227],\n          [-0.0436, -0.0408,  0.0362]]],\n\n\n        [[[ 0.0149, -0.0664, -0.0176],\n          [ 0.0604, -0.0538, -0.0335],\n          [ 0.0664, -0.0776, -0.0135]],\n\n         [[ 0.0090, -0.0303,  0.0666],\n          [-0.0421, -0.0260,  0.0003],\n          [-0.0087, -0.0589,  0.0237]],\n\n         [[ 0.0364, -0.0125, -0.0437],\n          [-0.0714,  0.0057, -0.0755],\n          [-0.0503,  0.0521,  0.0742]],\n\n         ...,\n\n         [[-0.0658, -0.0111,  0.0514],\n          [ 0.0726, -0.0650, -0.0284],\n          [ 0.0562, -0.0788,  0.0267]],\n\n         [[ 0.0506,  0.0538,  0.0632],\n          [-0.0220, -0.0435,  0.0303],\n          [ 0.0392,  0.0613,  0.0166]],\n\n         [[ 0.0075,  0.0575, -0.0676],\n          [-0.0565,  0.0098,  0.0439],\n          [ 0.0033, -0.0586, -0.0305]]],\n\n\n        [[[ 0.0717, -0.0398,  0.0347],\n          [-0.0189,  0.0493, -0.0753],\n          [-0.0265, -0.0647, -0.0762]],\n\n         [[-0.0344, -0.0658,  0.0813],\n          [ 0.0775,  0.0092,  0.0555],\n          [-0.0536, -0.0104,  0.0564]],\n\n         [[ 0.0585, -0.0754,  0.0176],\n          [ 0.0464,  0.0415, -0.0595],\n          [-0.0767,  0.0178, -0.0756]],\n\n         ...,\n\n         [[ 0.0405,  0.0767,  0.0459],\n          [ 0.0731,  0.0007, -0.0673],\n          [-0.0707, -0.0073, -0.0184]],\n\n         [[ 0.0576, -0.0678, -0.0513],\n          [-0.0443,  0.0832,  0.0222],\n          [ 0.0664, -0.0641, -0.0110]],\n\n         [[ 0.0201, -0.0602,  0.0625],\n          [-0.0795, -0.0108, -0.0306],\n          [-0.0069, -0.0754,  0.0686]]],\n\n\n        ...,\n\n\n        [[[-0.0282,  0.0557,  0.0529],\n          [ 0.0442, -0.0521,  0.0526],\n          [-0.0503,  0.0783, -0.0149]],\n\n         [[ 0.0705,  0.0137,  0.0115],\n          [-0.0697,  0.0566,  0.0390],\n          [ 0.0274,  0.0237,  0.0176]],\n\n         [[-0.0053,  0.0552,  0.0150],\n          [ 0.0185, -0.0828, -0.0556],\n          [ 0.0119, -0.0639,  0.0069]],\n\n         ...,\n\n         [[ 0.0758, -0.0561,  0.0736],\n          [ 0.0354,  0.0020, -0.0704],\n          [-0.0728,  0.0070, -0.0210]],\n\n         [[-0.0704, -0.0721, -0.0471],\n          [ 0.0515,  0.0612, -0.0683],\n          [ 0.0736, -0.0189, -0.0089]],\n\n         [[ 0.0766, -0.0191, -0.0560],\n          [ 0.0059,  0.0269,  0.0511],\n          [-0.0009,  0.0400,  0.0833]]],\n\n\n        [[[-0.0224, -0.0246, -0.0090],\n          [-0.0609, -0.0793, -0.0676],\n          [-0.0582,  0.0676,  0.0017]],\n\n         [[-0.0329, -0.0203, -0.0082],\n          [ 0.0803,  0.0792,  0.0266],\n          [ 0.0632, -0.0795, -0.0522]],\n\n         [[ 0.0823, -0.0328,  0.0202],\n          [-0.0287,  0.0696, -0.0042],\n          [-0.0168, -0.0114,  0.0425]],\n\n         ...,\n\n         [[-0.0449, -0.0095, -0.0251],\n          [ 0.0201,  0.0258, -0.0300],\n          [-0.0741, -0.0624,  0.0217]],\n\n         [[-0.0462, -0.0384, -0.0456],\n          [-0.0688, -0.0575,  0.0126],\n          [-0.0706, -0.0683, -0.0493]],\n\n         [[-0.0513,  0.0301, -0.0373],\n          [ 0.0523,  0.0076,  0.0665],\n          [-0.0355,  0.0827, -0.0600]]],\n\n\n        [[[ 0.0607,  0.0212, -0.0514],\n          [-0.0249,  0.0696,  0.0575],\n          [ 0.0194,  0.0120,  0.0354]],\n\n         [[ 0.0509, -0.0475,  0.0767],\n          [-0.0380, -0.0262,  0.0418],\n          [-0.0285, -0.0429, -0.0710]],\n\n         [[-0.0209,  0.0167,  0.0819],\n          [ 0.0330, -0.0331, -0.0510],\n          [ 0.0164,  0.0831, -0.0418]],\n\n         ...,\n\n         [[ 0.0469, -0.0809,  0.0497],\n          [-0.0369,  0.0198,  0.0341],\n          [ 0.0322, -0.0035,  0.0312]],\n\n         [[-0.0294, -0.0162, -0.0112],\n          [-0.0131,  0.0031, -0.0534],\n          [ 0.0499,  0.0160,  0.0448]],\n\n         [[ 0.0822, -0.0276, -0.0692],\n          [ 0.0415, -0.0398, -0.0719],\n          [ 0.0213,  0.0458, -0.0690]]]])\nNone tensor([ 0.0434, -0.0355, -0.0204, -0.0403,  0.0490, -0.0331, -0.0404,  0.0119])\nNone tensor([[[[-0.2587]],\n\n         [[-0.3400]],\n\n         [[-0.3423]],\n\n         [[ 0.1270]],\n\n         [[ 0.2513]],\n\n         [[-0.3049]],\n\n         [[-0.0996]],\n\n         [[ 0.0396]]]])\nNone tensor([0.1833])\n","output_type":"stream"}]},{"cell_type":"code","source":"model(images.to(torch.float32).to(DEVICE))","metadata":{"execution":{"iopub.status.busy":"2021-06-19T03:32:16.690782Z","iopub.execute_input":"2021-06-19T03:32:16.691190Z","iopub.status.idle":"2021-06-19T03:32:22.615545Z","shell.execute_reply.started":"2021-06-19T03:32:16.691152Z","shell.execute_reply":"2021-06-19T03:32:22.614550Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"tensor([[[[0.5228, 0.5228, 0.5228,  ..., 0.5228, 0.5228, 0.5228],\n          [0.5228, 0.5228, 0.5228,  ..., 0.5228, 0.5228, 0.5228],\n          [0.5228, 0.5228, 0.5228,  ..., 0.5228, 0.5228, 0.5228],\n          ...,\n          [0.5228, 0.5228, 0.5228,  ..., 0.5228, 0.5228, 0.5228],\n          [0.5228, 0.5228, 0.5228,  ..., 0.5228, 0.5228, 0.5228],\n          [0.5228, 0.5228, 0.5228,  ..., 0.5228, 0.5228, 0.5228]]],\n\n\n        [[[0.5228, 0.5228, 0.5228,  ..., 0.5228, 0.5228, 0.5228],\n          [0.5228, 0.5228, 0.5228,  ..., 0.5228, 0.5228, 0.5228],\n          [0.5228, 0.5228, 0.5228,  ..., 0.5228, 0.5228, 0.5228],\n          ...,\n          [0.5228, 0.5228, 0.5228,  ..., 0.5228, 0.5228, 0.5228],\n          [0.5228, 0.5228, 0.5228,  ..., 0.5228, 0.5228, 0.5228],\n          [0.5228, 0.5228, 0.5228,  ..., 0.5228, 0.5228, 0.5228]]]],\n       grad_fn=<SigmoidBackward>)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}